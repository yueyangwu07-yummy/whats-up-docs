{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA for What's Up, Docs?\n",
        "\n",
        "Baseline exploratory analysis of the DrivenData summarization dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "DATA_DIR = Path(\"../data\")\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "TEST_FEATURES_PATH = DATA_DIR / \"test_features.csv\"\n",
        "\n",
        "TRAIN_PATH, TEST_FEATURES_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_features_df = pd.read_csv(TEST_FEATURES_PATH)\n",
        "\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.describe(include=\"all\", datetime_is_numeric=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.assign(\n",
        "    text_char_len=train_df[\"text\"].str.len(),\n",
        "    text_word_len=train_df[\"text\"].str.split().str.len(),\n",
        "    summary_char_len=train_df[\"summary\"].str.len(),\n",
        "    summary_word_len=train_df[\"summary\"].str.split().str.len(),\n",
        ")\n",
        "\n",
        "train_df[[\"text_char_len\", \"text_word_len\", \"summary_char_len\", \"summary_word_len\"]].describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sns.histplot(train_df[\"text_word_len\"], bins=50, ax=axes[0])\n",
        "axes[0].set_title(\"Document Word Length Distribution\")\n",
        "axes[0].set_xlabel(\"Word count\")\n",
        "\n",
        "sns.histplot(train_df[\"summary_word_len\"], bins=50, ax=axes[1])\n",
        "axes[1].set_title(\"Summary Word Length Distribution\")\n",
        "axes[1].set_xlabel(\"Word count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_pairs = train_df.sample(3, random_state=42)\n",
        "for idx, row in sample_pairs.iterrows():\n",
        "    print(f\"paper_id: {row['paper_id']}\")\n",
        "    print(\"Document snippet:\")\n",
        "    print(row[\"text\"][:500].replace(\"\\n\", \" \") + \"...\")\n",
        "    print(\"Summary:\")\n",
        "    print(row[\"summary\"])\n",
        "    print(\"-\" * 80)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicate_docs = train_df.duplicated(subset=\"text\").sum()\n",
        "duplicate_summaries = train_df.duplicated(subset=\"summary\").sum()\n",
        "print(f\"Duplicate documents: {duplicate_docs}\")\n",
        "print(f\"Duplicate summaries: {duplicate_summaries}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_features_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Train samples: {len(train_df):,}\")\n",
        "print(f\"Test samples: {len(test_features_df):,}\")\n",
        "print(\"Average text word length:\", round(train_df[\"text_word_len\"].mean(), 2))\n",
        "print(\"Average summary word length:\", round(train_df[\"summary_word_len\"].mean(), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.assign(summary_to_text_ratio=train_df[\"summary_word_len\"] / train_df[\"text_word_len\"])\n",
        "train_df[\"summary_to_text_ratio\"].describe(percentiles=[0.5, 0.75, 0.9, 0.95])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.nlargest(3, \"text_word_len\")[[\"paper_id\", \"text_word_len\", \"summary_word_len\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "- Documents average ~6.3k words with a long tail past 9.7k words (90th percentile) and a max over 34k, so truncation or chunking is required.\n",
        "- Summaries are much shorter (mean ~184 words) with low variance, so we can keep targets largely intact.\n",
        "- Summary-to-text ratio has a median near 0.03, confirming highly abstractive style.\n",
        "- No missing values detected in `text` or `summary`; data quality looks clean aside from length outliers.\n",
        "- Sample pairs show academic, multi-paragraph structure; SentencePiece tokenizer defaults should cope but we must watch token budgets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
